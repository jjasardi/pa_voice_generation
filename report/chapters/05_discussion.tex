\newpage
\section{Discussion}

The evaluation of speech is subjective due to the complexity of human perception. The influence of training data and inference iterations on the quality of speech synthesis is a crucial aspect to consider. This can be observed with TorToise, which demonstrated remarkable naturalness in its synthesized output, attributed to the extensive training data set and a high number of inference iterations. However, the speaker similarity aspect did not exhibit a proportional improvement, as evidenced by the comparable speaker similarity results observed in TorToise, trained on a significantly larger data set, and VALL-E X, trained on a comparatively smaller data set. The nature of the training data further influences the output characteristics, evident in TorToise's distinctive book reading style, a reflection of its primary training on audio books.

The candidate generation played a significant role in obtaining natural synthesized speech. TorToise seamlessly handled this step through the Contrastive Language-Voice Pretrained Transformer (CLVP), automating the generation and selection of optimal speech tokens. Additionally three output candidates were generated and the best one was manually selected. In contrast, VALL-E X required manual generation of multiple candidates by synthesizing the same sentence repeatedly. Multiple candidates were needed especially for sentences featuring complex phonemes and uncommon words in VALL-E X, highlighting potential limitations in the diversity of its training data concerning these linguistic elements.
The quantity of training data alone does not guarantee success, as observed in Real-Time Voice Cloning. Despite being trained on a larger dataset compared to VALL-E X, Real-Time Voice Cloning, being an earlier tool, did not generate natural sounding speech. This underscores the importance of recent advancements in model architectures in \gls{dnn}.

%own mistakes?

The results from this research shows the current capabilities of \gls{dnn}s synthesizing speech and how the quality can be, when generating speech for potential scams or spoofing attacks. Most of the generated audio is not usable in voice spoofing attacks due to clearly being recognized as generated speech with robotic-sounding artefacts, wrong intonations or bad-sounding prosody. These negative properties can be diminished when using them in situations, where worse audio quality is a plausibility. For example phone calls with bad audio quality either due to a bad microphone or bad reception while going through tunnels or calling from remote areas with less signal. With modern voice-over-internet-protocol calls the quality is usually good enough to notice synthesized speech. Considering the long generation times the need of a pre-generated response set is mandatory for a spoofing attack over a phone call. Additionally this means generating a lot of different responses to accommodate many situations in a phone call. A more ideal situation for an attacker is the use of voice messages, so sending recorded speech in replacement of a phone call. There, an attacker has much more time to generate the best possible response while also having the option to generate speech displaying emotions. Though with voice messages one does need to have access to a verified device from the targeted person to properly impersonate them. Sending voice messages with synthesized speech can be interpreted as more plausible as just plain text, when having access to a verified device through theft or spoofing. The best defense against these attacks is to ask the possible attacker on the phone for a completely random passphrase from a shared experience between them or a more elaborate system ask them for an explanation of a word from the dictionary the longer the explanation the better the system. For example: "Can you please explain to me what a guitar is?".

All these reasons naturally change when one tries to imitate a well-known person with a lot of recorded material readily available, for example celebrities, politicians, CEOs or people in general working in front of a camera or microphone such as actors, news anchors, journalists, podcast hosts et cetera. With extensive audio material one can even train \gls{dnn}s on these persons to achieve even more convincing synthesized speech from these models. If one abstracts this imitation problem to the extreme, it condenses into a probabilistic problem where each audio file is a sequence of binary data that translated into sound waves could be unrecognizable to the binary sequence of a recording of a real person. Obviously with so many variables it will take a lot of time to produce such results, but at a certain point the fake voice sounds exactly the same as the real voice to a loudspeaker. Such problems can most often only be solved by cryptography, meaning in the future where such perfect imitations are possible, the best way to verify the authenticity of any voice transmission will be a Diffie-Hellman key exchange with verified sources\cite{maurer2000diffie}.